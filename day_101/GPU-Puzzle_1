import numpy as np
from numba import cuda

# 1) Define the CUDA "map" kernel
@cuda.jit
def add_ten_kernel(a, out):
    idx = cuda.grid(1)             # 1D global thread index :contentReference[oaicite:5]{index=5}
    if idx < a.size:               # Bounds check :contentReference[oaicite:6]{index=6}
        out[idx] = a[idx] + 10     # Elementwise add 10 :contentReference[oaicite:7]{index=7}

# 2) Host-side setup
n = 1024                           # Vector length
a_host = np.arange(n, dtype=np.float32)  # Example input :contentReference[oaicite:8]{index=8}
# Transfer input to device
a_dev = cuda.to_device(a_host)     # Host→device copy :contentReference[oaicite:9]{index=9}
# Allocate output on device
out_dev = cuda.device_array_like(a_host)  # Device array allocation :contentReference[oaicite:10]{index=10}

# 3) Launch configuration
threads_per_block = 128
blocks_per_grid = (n + threads_per_block - 1) // threads_per_block  # Grid sizing :contentReference[oaicite:11]{index=11}

# 4) Kernel launch
add_ten_kernel[blocks_per_grid, threads_per_block](a_dev, out_dev)  # Invoke kernel :contentReference[oaicite:12]{index=12}

# 5) Copy result back to host
out_host = out_dev.copy_to_host()  # Device→host copy :contentReference[oaicite:13]{index=13}

# 6) Verify
print(out_host[:10])  # Should print [10,11,12,...,19]
