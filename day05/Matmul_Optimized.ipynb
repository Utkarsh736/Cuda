{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "lsDszHe45wTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os,math,sys,torch,re,numpy as np\n",
        "from types import SimpleNamespace as ns\n",
        "from collections import namedtuple"
      ],
      "metadata": {
        "id": "nOjeYxyJ6N8w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim3 = namedtuple('dim3', ['x','y','z'], defaults=(1,1))"
      ],
      "metadata": {
        "id": "FRcPglZW6Yc6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = dim3(2,3)\n",
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rzHcS6u6gX6",
        "outputId": "d2d28e97-7aae-4607-f7c5-45758e15f389"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dim3(x=2, y=3, z=1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d.x, d.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVaSHatK6iOH",
        "outputId": "060e4681-2ac8-4af6-b1b8-a24684373a3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=2, linewidth=140)\n",
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
      ],
      "metadata": {
        "id": "cIFkItlg6lpj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.insert(0, '..')"
      ],
      "metadata": {
        "id": "uc4SqXD563Iw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import show_img, load_cuda, cuda_begin, cdiv"
      ],
      "metadata": {
        "id": "BIbJmgNB65m0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q wurlitzer ninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0o2VrJ6DUtz",
        "outputId": "484f23c4-e0ed-454f-dd54-76e90bc55f55"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/422.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/422.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext wurlitzer"
      ],
      "metadata": {
        "id": "VChSBSsa6-Yk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
        "torch.manual_seed(42);"
      ],
      "metadata": {
        "id": "8UWRmffX7yWP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = torch.rand(5120, 256)\n",
        "m1s = m1[:4]\n",
        "m2 = torch.rand(256, 5120)\n",
        "m2s = m2[:,:4]"
      ],
      "metadata": {
        "id": "F-fxI_fv77-B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reminder"
      ],
      "metadata": {
        "id": "owVFnYoK8L6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2d Python Kernel"
      ],
      "metadata": {
        "id": "ez6B-dVs8Oa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def blk_kernel2d(f, blocks, threads, *args):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            for j0 in range(threads.y):\n",
        "                for j1 in range(threads.x): f(dim3(i1,i0), dim3(j1,j0), threads, *args)"
      ],
      "metadata": {
        "id": "DQLahqDT8Qts"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_bk(blockIdx, threadIdx, blockDim, m, n, out, h, w, k):\n",
        "    r = blockIdx.y*blockDim.y + threadIdx.y\n",
        "    c = blockIdx.x*blockDim.x + threadIdx.x\n",
        "\n",
        "    if (r>=h or c>=w): return\n",
        "    o = 0.\n",
        "    for i in range(k): o += m[r*k+i] * n[i*w+c]\n",
        "    out[r*w+c] = o"
      ],
      "metadata": {
        "id": "BUynakpJ8W8A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_2d(m, n):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(16,16)\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    blk_kernel2d(matmul_bk, blocks, tpb,\n",
        "                 m.flatten(), n.flatten(), output.flatten(), h, w, k)\n",
        "    return output"
      ],
      "metadata": {
        "id": "dVreWlt58YWE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isclose(matmul_2d(m1s, m2s), m1s@m2s).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzk-YlpR8Z1u",
        "outputId": "61e4f931-0b0c-40de-b296-e506f1fe7a0c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA"
      ],
      "metadata": {
        "id": "-9dfJ_Dc8cMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "__global__ void matmul_k(float* m, float* n, float* out, int h, int w, int k) {\n",
        "    int r = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (r>=h || c>=w) return;\n",
        "    float o = 0;\n",
        "    for (int i = 0; i<k; ++i) o += m[r*k+i] * n[i*w+c];\n",
        "    out[r*w+c] = o;\n",
        "}\n",
        "\n",
        "torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h = m.size(0);\n",
        "    int w = n.size(1);\n",
        "    int k = m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "\n",
        "    dim3 tpb(16,16);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "    matmul_k<<<blocks, tpb>>>(\n",
        "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "25jV-NTX8gGQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = 'matmul'"
      ],
      "metadata": {
        "id": "no_uBnhs8sMu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sig(fname, src):\n",
        "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
        "    return res[0]+';' if res else None"
      ],
      "metadata": {
        "id": "SXS3Hnvh8ueL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_src = get_sig(fname, cuda_src)\n",
        "cpp_src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ocz8W8kp9Fk_",
        "outputId": "f7633a8a-d412-46de-82f8-cef2b0cd6d4c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch::Tensor matmul(torch::Tensor m, torch::Tensor n);'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "module = load_cuda(cuda_src, cpp_src, [fname])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJBgVXrH9YXH",
        "outputId": "07ae3239-4338-477a-fe16-2052331469a6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1c, m2c = m1.contiguous().cuda(), m2.contiguous().cuda()"
      ],
      "metadata": {
        "id": "5aHH77HA9edJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module.matmul(m1c, m2c).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FruTSw999o4F",
        "outputId": "7e886773-9e8d-4799-894f-645559643cae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5120, 5120])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isclose(module.matmul(m1c,m2c), m1c@m2c).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMLQeaXM99h-",
        "outputId": "dbef25a8-aa97-4b10-cc60-36b45aae8c24"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10\n",
        "module.matmul(m1c,m2c)\n",
        "torch.cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfrxi4-899e6",
        "outputId": "f9f7b9b8-5d47-4f98-f1d4-db43beca8af8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 ms ± 3.78 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shared Memory"
      ],
      "metadata": {
        "id": "Qenamp4H-FM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python"
      ],
      "metadata": {
        "id": "T1ImYn3q99Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.zeros(5)\n",
        "b,c = a[:3],a[3:]"
      ],
      "metadata": {
        "id": "Rc5XWdox99W7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b[1] = 2\n",
        "c[0] = 6\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZggjopJ99TS",
        "outputId": "47cc01d8-1a69-4e6e-b973-f4005df4a05b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 0., 6., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def blk_kernel2d_shar(f, blocks, threads, sh_sz, *args, **kwargs):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            shared = torch.zeros(sh_sz)\n",
        "            f(dim3(i1,i0), threads, shared, *args, **kwargs)"
      ],
      "metadata": {
        "id": "7rPHoWsw99Oc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):\n",
        "    shar_sz = tw*tw\n",
        "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
        "\n",
        "    for ph in range(cdiv(k,tw)):\n",
        "        idx = ph*tw\n",
        "        # fill shared\n",
        "        for tr in range(blockDim.y):\n",
        "            for tc in range(blockDim.x):\n",
        "                r,c = blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n",
        "                ms[tr*tw+tc] = m[ tc+idx + r*k] if r<h and idx+tc<k else 0.\n",
        "                ns[tr*tw+tc] = n[(tr+idx)*w +c] if c<w and idx+tr<k else 0.\n",
        "\n",
        "        # do dotprods from shared\n",
        "        for tr in range(blockDim.y):\n",
        "            for tc in range(blockDim.x):\n",
        "                r,c = blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n",
        "                for i in range(tw):\n",
        "                    if r*w+c<len(out): out[r*w+c] += ms[tr*tw+i] * ns[tw*i+tc]"
      ],
      "metadata": {
        "id": "PteQbssu-Qy-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_2d(m, n, tw=16):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(tw,tw)\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
        "                      m.flatten(), n.flatten(), output.flatten(),\n",
        "                      h, w, k, tw=tw)\n",
        "    return output"
      ],
      "metadata": {
        "id": "wVW3NXdG-QvW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1s.shape, m2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdtKj2rX-Qp8",
        "outputId": "83d0ecd1-a495-4e03-8424-8bdd0068ee8c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 256]), torch.Size([256, 5120]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isclose(matmul_2d(m1s, m2s, tw=16), m1s@m2s).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFOXV7OC-QHx",
        "outputId": "cda121f3-95df-47f2-c494-207545521d22"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python run_threads"
      ],
      "metadata": {
        "id": "zW1ju1MsAbgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_threads(f, blockDim, *args, **kwargs):\n",
        "    for i0 in range(blockDim.y):\n",
        "        for i1 in range(blockDim.x): f(i0, i1, *args, **kwargs)"
      ],
      "metadata": {
        "id": "ThxEqmauAecy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_tiled_bk(blockIdx, blockDim, shared, m, n, out, h, w, k, tw):\n",
        "    shar_sz = tw*tw\n",
        "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
        "\n",
        "    def get_rc(tr, tc): return blockIdx.y*blockDim.y + tr, blockIdx.x*blockDim.x + tc\n",
        "\n",
        "    def fill_shared_tk(tr, tc, ph):\n",
        "        r,c = get_rc(tr, tc)\n",
        "        ms[tr*tw+tc] = m[ tc + ph*tw + r*k] if r<h and (ph*tw+tc)<k else 0.\n",
        "        ns[tr*tw+tc] = n[(tr + ph*tw)*w +c] if c<w and (ph*tw+tr)<k else 0.\n",
        "\n",
        "    def dotprod_tk(tr, tc):\n",
        "        r,c = get_rc(tr, tc)\n",
        "        for i in range(tw):\n",
        "            if r*w+c<len(out): out[r*w+c] += ms[tr*tw+i] * ns[tw*i+tc]\n",
        "\n",
        "    for ph in range(int(math.ceil(k/tw))):\n",
        "        run_threads(fill_shared_tk, blockDim, ph)\n",
        "        run_threads(dotprod_tk, blockDim)"
      ],
      "metadata": {
        "id": "1H1HAKdtAfv6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_2d(m, n, tw=16):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(tw,tw)\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
        "                      m.flatten(), n.flatten(), output.flatten(),\n",
        "                      h, w, k, tw=tw)\n",
        "    return output"
      ],
      "metadata": {
        "id": "FNZd25uGAhNt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1s.shape, m2s.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt14666JAnQm",
        "outputId": "d2f98f57-f875-4c5c-8fa4-ee842add48ce"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 256]), torch.Size([256, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isclose(matmul_2d(m1s, m2s, tw=16), m1s@m2s).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2A41yaMAoiN",
        "outputId": "76b13a12-0a58-4e65-d728-4feb8e45fb79"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python threads"
      ],
      "metadata": {
        "id": "EtbPQEweAq5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "from threading import Barrier, Thread\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ],
      "metadata": {
        "id": "xChBsXj_AtTz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def g(x, sb):\n",
        "    print(x)\n",
        "    sb.wait()\n",
        "    print(-x)\n",
        "    sb.wait()\n",
        "    print(x*10)"
      ],
      "metadata": {
        "id": "U9W4yBp9AviE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 3\n",
        "sb = Barrier(num)\n",
        "with ThreadPoolExecutor(num) as ex: list(ex.map(lambda i: g(i,sb), range(1,num+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HghE0GqAxHQ",
        "outputId": "5815b75c-15eb-48bb-dde6-6a3eea80238e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "-3-2\n",
            "-1\n",
            "\n",
            "3020\n",
            "10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def blk_kernel2d_shar(f, blocks, tpb, sh_sz, *args, **kwargs):\n",
        "    for i0 in range(blocks.y):\n",
        "        for i1 in range(blocks.x):\n",
        "            shar = torch.zeros(sh_sz)\n",
        "            syncb = Barrier(tpb.y*tpb.x)\n",
        "            threads = [Thread(target=f, args=(dim3(i1,i0), dim3(p,o), tpb, shar, syncb, *args), kwargs=kwargs)\n",
        "                       for o in range(tpb.y) for p in range(tpb.x)]\n",
        "            for tr in threads: tr.start()\n",
        "            for tr in threads: tr.join()"
      ],
      "metadata": {
        "id": "otv3S_snAyWz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_tiled_bk(blockIdx, threadIdx, blockDim, shared, syncb, m, n, out, h, w, k, tw):\n",
        "    tc,tr = threadIdx.x,threadIdx.y\n",
        "    r = blockIdx.y*blockDim.y + tr\n",
        "    c = blockIdx.x*blockDim.x + tc\n",
        "\n",
        "    shar_sz = tw*tw\n",
        "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
        "\n",
        "    p = 0.\n",
        "    for ph in range(cdiv(k,tw)):\n",
        "        ms[tr*tw+tc] = m[ tc + ph*tw + r*k] if r<h and (ph*tw+tc)<k else 0.\n",
        "        ns[tr*tw+tc] = n[(tr + ph*tw)*w +c] if c<w and (ph*tw+tr)<k else 0.\n",
        "        syncb.wait()\n",
        "        for i in range(tw): p += ms[tr*tw+i] * ns[tw*i+tc]\n",
        "        syncb.wait()\n",
        "\n",
        "    if (r<h and c<w): out[r*w + c] = p"
      ],
      "metadata": {
        "id": "96XguIIJBI_4"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_2d(m, n, tw=16):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    output = torch.zeros(h, w, dtype=m.dtype)\n",
        "    tpb = dim3(tw,tw)\n",
        "    blocks = dim3(cdiv(w,tpb.x), cdiv(h,tpb.y))\n",
        "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
        "                      m.flatten(), n.flatten(), output.flatten(),\n",
        "                      h, w, k, tw=tw)\n",
        "    return output"
      ],
      "metadata": {
        "id": "Z65l4wzABKzA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isclose(matmul_2d(m1s, m2s, tw=8), m1s@m2s).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcFB7QubBNQM",
        "outputId": "fcbdcd29-247f-48ab-e1fd-aa2f9667ac26"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA dynamic shared"
      ],
      "metadata": {
        "id": "-txYNCGuBPRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k, int tw) {\n",
        "    int tc=threadIdx.x, tr=threadIdx.y;\n",
        "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
        "\n",
        "    extern __shared__ float ms[];\n",
        "    float *ns = &ms[tw*tw];\n",
        "\n",
        "    float p = 0.0f;\n",
        "    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n",
        "        int idx = ph*tw;\n",
        "        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
        "        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
        "        __syncthreads();\n",
        "        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (r<h && c<w) out[r*w + c] = p;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "B_l5ZRztBSUt"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src += r'''\n",
        "torch::Tensor matmul_dyn(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "\n",
        "    /*\n",
        "    // Commented out section demonstrating basic idea of dynamic size calculation\n",
        "    cudaDeviceProp devProp;\n",
        "    CUDA_ERR(cudaGetDeviceProperties(&devProp, 0));\n",
        "    int maxThreads = devProp.maxThreadsPerBlock;\n",
        "    size_t requiredSize = static_cast<size_t>(maxThreads) * 2 * sizeof(float);\n",
        "    size_t size = min(devProp.sharedMemPerBlock, requiredSize);\n",
        "    int TW = std::sqrt(maxThreads);\n",
        "    */\n",
        "\n",
        "    // We just set size fixed for now\n",
        "    int TW = 16;\n",
        "    size_t size = TW*TW * 2 * sizeof(float);\n",
        "    dim3 tpb(TW,TW);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "    matmul_k<<<blocks,tpb,size>>>(\n",
        "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k, TW);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "p-y4_r7YBYTl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = 'matmul_dyn'"
      ],
      "metadata": {
        "id": "4XYKQ5pCBbcT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_src = get_sig(fname, cuda_src)"
      ],
      "metadata": {
        "id": "1kdfRWzaBc_2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module = load_cuda(cuda_src, cpp_src, [fname], opt=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh-Ebf81BelE",
        "outputId": "95df01a3-fd51-4655-eb79-38018e33f548"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isclose(module.matmul_dyn(m1c,m2c), m1c@m2c).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auhg2QxQBiBt",
        "outputId": "34994228-1530-48e6-cbcd-b1fca9888660"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10\n",
        "module.matmul_dyn(m1c,m2c)\n",
        "torch.cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nArvrE-Blvt",
        "outputId": "135b8b5a-f543-4d48-fd05-d771c4318a32"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26.2 ms ± 2.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CUDA static shared"
      ],
      "metadata": {
        "id": "plZND7wVBos5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "constexpr int tw = 16;\n",
        "\n",
        "__global__ void matmul_ks(float *m, float *n, float *out, int h, int w, int k) {\n",
        "    __shared__ float ms[tw][tw], ns[tw][tw];\n",
        "    int tc=threadIdx.x, tr=threadIdx.y;\n",
        "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
        "\n",
        "    float p=0.0f;\n",
        "    for (int ph=0; ph < cdiv(k,tw); ++ph) {\n",
        "        int idx = ph*tw;\n",
        "        ms[tr][tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
        "        ns[tr][tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
        "        __syncthreads();\n",
        "        for (int i=0; i<tw; ++i) p += ms[tr][i] * ns[i][tc];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (r<h && c<w) out[r*w + c] = p;\n",
        "}\n",
        "\n",
        "torch::Tensor matmul_static(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "    dim3 tpb(tw,tw);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "    matmul_ks<<<blocks,tpb>>>(m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "RVkhSYPmBlq7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = 'matmul_static'\n",
        "cpp_src = get_sig(fname, cuda_src)\n",
        "module = load_cuda(cuda_src, cpp_src, [fname])\n",
        "torch.isclose(module.matmul_static(m1c,m2c), m1c@m2c).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3i3E3FaBlml",
        "outputId": "471ccbc0-26a9-4f31-a62e-c67480475536"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10\n",
        "module.matmul_static(m1c,m2c)\n",
        "torch.cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce8gBTJ5BljU",
        "outputId": "44bd9806-7505-4d4b-c1e3-d006b409eecf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21.4 ms ± 3.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numba"
      ],
      "metadata": {
        "id": "ZXIlLTFeByoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "from numba.cuda import as_cuda_array as ca"
      ],
      "metadata": {
        "id": "biLww276BzyD"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def matmul_k_numba(m, n, out, tw):\n",
        "    cbi,cbd,tid = cuda.blockIdx,cuda.blockDim,cuda.threadIdx\n",
        "    tc,tr = tid.x,tid.y\n",
        "    r,c = cbi.y * cbd.y + tr, cbi.x * cbd.x + tc\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "\n",
        "    shar = cuda.shared.array(0, dtype=np.float32)\n",
        "    ms,ns = shar[:tw*tw],shar[tw*tw:2*tw*tw]\n",
        "\n",
        "    p = np.float32(0.0)\n",
        "    for ph in range(math.ceil(k/tw)):\n",
        "        idx = ph*tw\n",
        "        ms[tr*tw+tc] = m[r, tc+idx] if r<h and idx+tc<k else 0.\n",
        "        ns[tr*tw+tc] = n[tr+idx, c] if c<w and idx+tr<k else 0.\n",
        "        cuda.syncthreads()\n",
        "        for i in range(tw): p += ms[tr*tw+i] * ns[i*tw+tc]\n",
        "        cuda.syncthreads()\n",
        "    if r < h and c < w: out[r, c] = p"
      ],
      "metadata": {
        "id": "LEeh8eVDB1IK"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matmul_2d_numba(m, n, tw=16):\n",
        "    h,k  = m.shape\n",
        "    k2,w = n.shape\n",
        "    assert k==k2, \"Size mismatch!\"\n",
        "    out = torch.zeros(h, w, dtype=m.dtype, device=m.device)\n",
        "    dyn_shared_mem_size = 2 * tw * tw * 4\n",
        "    tpb = tw,tw\n",
        "    blocks = cdiv(w,tpb[0]), cdiv(h,tpb[1])\n",
        "    matmul_k_numba[blocks, tpb, 0, dyn_shared_mem_size](ca(m), ca(n), ca(out), tw)\n",
        "    return out"
      ],
      "metadata": {
        "id": "3sWg4jWLB4Ks"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.isclose(matmul_2d_numba(m1c,m2c), m1c@m2c).all()"
      ],
      "metadata": {
        "id": "F_7BwpU3B8VZ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%timeit -n 10\n",
        "# matmul_2d_numba(m1c,m2c)\n",
        "# torch.cuda.synchronize()"
      ],
      "metadata": {
        "id": "N2EGT25eCS3Y"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra: Optimised Dynamic CUDA with Template"
      ],
      "metadata": {
        "id": "9QtXfpShCV14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "template<int tw>\n",
        "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k) {\n",
        "    int tc=threadIdx.x, tr=threadIdx.y;\n",
        "    int r=blockIdx.y*blockDim.y+tr, c=blockIdx.x*blockDim.x+tc;\n",
        "    extern __shared__ float ms[];\n",
        "    float *ns = &ms[tw*tw];\n",
        "\n",
        "    float p = 0.0f;\n",
        "    for (int ph = 0; ph < cdiv(k,tw); ++ph) {\n",
        "        int idx = ph*tw;\n",
        "        ms[tr*tw + tc] = r<h && idx+tc<k ? m[ tc+idx + r*k ] : 0.0f;\n",
        "        ns[tr*tw + tc] = c<w && idx+tr<k ? n[(tr+idx)*w + c] : 0.0f;\n",
        "        __syncthreads();\n",
        "        for (int i=0; i<tw; ++i) p += ms[tr*tw + i] * ns[tw*i + tc];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (r<h && c<w) out[r*w + c] = p;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "25uxqzg5CVSd"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src += r'''\n",
        "torch::Tensor matmul_dyn1(torch::Tensor m, torch::Tensor n) {\n",
        "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
        "    int h=m.size(0), w=n.size(1), k=m.size(1);\n",
        "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
        "    auto output = torch::zeros({h, w}, m.options());\n",
        "    int TW = 16; // TODO: Calculate this dynamically\n",
        "    size_t size = TW*TW*2 * sizeof(float) + 1;\n",
        "    dim3 tpb(TW,TW);\n",
        "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "\n",
        "    auto f = [&](auto kf) { kf<<<blocks, tpb, size>>>(\n",
        "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
        "    };\n",
        "    switch(TW) {\n",
        "        case 8: f(matmul_k<8>); break;\n",
        "        case 16: f(matmul_k<16>); break;\n",
        "        case 32: f(matmul_k<32>); break;\n",
        "        default: break;\n",
        "    }\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "2D4njCVsCVH1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "fname = 'matmul_dyn1'\n",
        "cpp_src = get_sig(fname, cuda_src)\n",
        "module = load_cuda(cuda_src, cpp_src, [fname], opt=True)\n",
        "func = getattr(module, fname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isSRflScCVFl",
        "outputId": "e2ba07ea-2e96-4711-e374-26d349a667b4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 798 ms, sys: 81 ms, total: 879 ms\n",
            "Wall time: 1min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.isclose(func(m1c,m2c), m1c@m2c).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR7D9bovCVBo",
        "outputId": "b6f960c7-4a0d-4fdc-8edb-4e87dd759dd6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit -n 10\n",
        "func(m1c,m2c)\n",
        "torch.cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nh3W0haCj-_",
        "outputId": "6b4b508a-e043-4efb-85f0-6a2c7a5cba20"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 ms ± 2.96 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nN1JUPGVFVOB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
